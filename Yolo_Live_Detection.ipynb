{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8db3187-1e17-47b3-af88-779c1e5aba43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.166-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from ultralytics) (2.7.1)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Using cached torchvision-0.22.1-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Using cached ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
      "Requirement already satisfied: filelock in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saiprithi\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Using cached ultralytics-8.3.166-py3-none-any.whl (1.0 MB)\n",
      "Using cached torchvision-0.22.1-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "Using cached ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, torchvision, ultralytics\n",
      "Successfully installed torchvision-0.22.1 ultralytics-8.3.166 ultralytics-thop-2.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97af84e8-453d-4732-8a36-41d6afab2b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\saiprithi\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33faa64f-90bb-4c75-8ddd-f3aee3fb19e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolo-Weights\\yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6.25M/6.25M [00:01<00:00, 4.34MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 tv, 397.0ms\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> tvmonitor\n",
      "Speed: 18.1ms preprocess, 397.0ms inference, 15.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 233.4ms\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> chair\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> person\n",
      "Speed: 12.7ms preprocess, 233.4ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 215.1ms\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Speed: 6.1ms preprocess, 215.1ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 222.1ms\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> chair\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "Speed: 8.4ms preprocess, 222.1ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 207.2ms\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> chair\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Speed: 5.1ms preprocess, 207.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 207.7ms\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> chair\n",
      "Confidence ---> 0.45\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Speed: 4.3ms preprocess, 207.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 227.6ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> chair\n",
      "Speed: 6.3ms preprocess, 227.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 232.1ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Confidence ---> 0.63\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> chair\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Speed: 7.1ms preprocess, 232.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 191.7ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> chair\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Speed: 5.2ms preprocess, 191.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 190.6ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> chair\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "Speed: 4.7ms preprocess, 190.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 1 laptop, 251.2ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.76\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> chair\n",
      "Speed: 3.8ms preprocess, 251.2ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 371.1ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> chair\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Speed: 5.3ms preprocess, 371.1ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 268.4ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Speed: 13.3ms preprocess, 268.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 304.2ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Speed: 8.8ms preprocess, 304.2ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 286.3ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "Speed: 10.6ms preprocess, 286.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 321.4ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Speed: 11.2ms preprocess, 321.4ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 330.8ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Confidence ---> 0.63\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Speed: 6.6ms preprocess, 330.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 302.9ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Speed: 5.2ms preprocess, 302.9ms inference, 8.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 306.7ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.56\n",
      "Class name --> person\n",
      "Confidence ---> 0.56\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Speed: 7.6ms preprocess, 306.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 278.2ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Speed: 7.0ms preprocess, 278.2ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 308.4ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "Speed: 8.2ms preprocess, 308.4ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 413.5ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Speed: 5.5ms preprocess, 413.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 tv, 290.5ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.56\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> tvmonitor\n",
      "Speed: 5.2ms preprocess, 290.5ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 laptop, 429.1ms\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Speed: 7.0ms preprocess, 429.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 286.2ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "Speed: 5.7ms preprocess, 286.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 344.5ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 5.5ms preprocess, 344.5ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 358.7ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 10.3ms preprocess, 358.7ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 laptop, 348.8ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> laptop\n",
      "Speed: 7.4ms preprocess, 348.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 355.1ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "Speed: 6.7ms preprocess, 355.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 452.8ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> chair\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Speed: 7.2ms preprocess, 452.8ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 398.0ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> chair\n",
      "Speed: 8.7ms preprocess, 398.0ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 424.8ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "Speed: 7.6ms preprocess, 424.8ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 laptop, 444.5ms\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Speed: 16.9ms preprocess, 444.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 laptop, 420.9ms\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.74\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.62\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Speed: 4.8ms preprocess, 420.9ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 451.9ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> chair\n",
      "Speed: 12.2ms preprocess, 451.9ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 laptop, 367.2ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Speed: 5.3ms preprocess, 367.2ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 299.6ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> chair\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 6.4ms preprocess, 299.6ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 laptop, 264.7ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 4.7ms preprocess, 264.7ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 1 chair, 270.8ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> chair\n",
      "Confidence ---> 0.46\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 5.3ms preprocess, 270.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 chair, 1 laptop, 280.4ms\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> chair\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Speed: 5.0ms preprocess, 280.4ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 chair, 278.9ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> chair\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "Speed: 5.2ms preprocess, 278.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 2 chairs, 312.6ms\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.8\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> chair\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> chair\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Speed: 5.4ms preprocess, 312.6ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 292.4ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> chair\n",
      "Speed: 4.3ms preprocess, 292.4ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 242.8ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "Confidence ---> 0.62\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> chair\n",
      "Speed: 4.3ms preprocess, 242.8ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 287.4ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.56\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> chair\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Speed: 6.5ms preprocess, 287.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 309.6ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 8.6ms preprocess, 309.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 289.8ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 4.4ms preprocess, 289.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 chair, 284.0ms\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.63\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> chair\n",
      "Speed: 5.3ms preprocess, 284.0ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 265.6ms\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.68\n",
      "Class name --> chair\n",
      "Confidence ---> 0.62\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Speed: 4.2ms preprocess, 265.6ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 260.1ms\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> chair\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> person\n",
      "Speed: 4.9ms preprocess, 260.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 260.3ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> chair\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "Speed: 4.1ms preprocess, 260.3ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 343.6ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> chair\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Speed: 5.7ms preprocess, 343.6ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 282.3ms\n",
      "Confidence ---> 0.66\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Speed: 4.8ms preprocess, 282.3ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 239.3ms\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Speed: 5.1ms preprocess, 239.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 283.2ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.63\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Speed: 4.1ms preprocess, 283.2ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 291.4ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Confidence ---> 0.62\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> chair\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Speed: 5.1ms preprocess, 291.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 269.6ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> chair\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 5.3ms preprocess, 269.6ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 242.0ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> chair\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Speed: 6.1ms preprocess, 242.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 1 laptop, 245.5ms\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> chair\n",
      "Confidence ---> 0.34\n",
      "Class name --> laptop\n",
      "Speed: 4.5ms preprocess, 245.5ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 346.0ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.76\n",
      "Class name --> person\n",
      "Confidence ---> 0.62\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> chair\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Speed: 5.1ms preprocess, 346.0ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 2 chairs, 1 laptop, 249.6ms\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.56\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> chair\n",
      "Confidence ---> 0.26\n",
      "Class name --> chair\n",
      "Confidence ---> 0.26\n",
      "Class name --> laptop\n",
      "Speed: 4.2ms preprocess, 249.6ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 1 chair, 282.1ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.56\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> chair\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 4.8ms preprocess, 282.1ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 laptop, 267.5ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Confidence ---> 0.63\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "Speed: 4.2ms preprocess, 267.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 laptop, 385.7ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "Speed: 4.8ms preprocess, 385.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 laptop, 308.7ms\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.57\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Speed: 4.6ms preprocess, 308.7ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 1 chair, 293.2ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> chair\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Speed: 4.1ms preprocess, 293.2ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 1 laptop, 468.3ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.81\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> chair\n",
      "Speed: 4.7ms preprocess, 468.3ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 1 laptop, 273.1ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> chair\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Speed: 4.3ms preprocess, 273.1ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 1 laptop, 273.3ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.62\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> chair\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Speed: 4.1ms preprocess, 273.3ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 1 laptop, 395.0ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.62\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.56\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> chair\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Speed: 5.1ms preprocess, 395.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 laptop, 290.0ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 4.4ms preprocess, 290.0ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 250.7ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Speed: 4.4ms preprocess, 250.7ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 287.9ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.53\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Speed: 4.6ms preprocess, 287.9ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 276.9ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Speed: 6.4ms preprocess, 276.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 268.4ms\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> person\n",
      "Speed: 4.6ms preprocess, 268.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 274.3ms\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Speed: 4.4ms preprocess, 274.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 285.1ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Speed: 4.3ms preprocess, 285.1ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 251.5ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Speed: 4.9ms preprocess, 251.5ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 317.9ms\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.86\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Speed: 6.0ms preprocess, 317.9ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 291.5ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "Speed: 4.4ms preprocess, 291.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 236.5ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "Speed: 5.8ms preprocess, 236.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 314.2ms\n",
      "Confidence ---> 0.84\n",
      "Class name --> person\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "Speed: 4.2ms preprocess, 314.2ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 310.3ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.62\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> person\n",
      "Speed: 7.5ms preprocess, 310.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 254.0ms\n",
      "Confidence ---> 0.83\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.51\n",
      "Class name --> person\n",
      "Speed: 5.9ms preprocess, 254.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 299.5ms\n",
      "Confidence ---> 0.87\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 4.4ms preprocess, 299.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 237.6ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.75\n",
      "Class name --> person\n",
      "Confidence ---> 0.63\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "Speed: 6.0ms preprocess, 237.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 216.2ms\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Speed: 6.2ms preprocess, 216.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 283.4ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.72\n",
      "Class name --> person\n",
      "Confidence ---> 0.6\n",
      "Class name --> person\n",
      "Confidence ---> 0.36\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Speed: 6.1ms preprocess, 283.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 247.4ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "Confidence ---> 0.56\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Speed: 4.1ms preprocess, 247.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 211.2ms\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "Confidence ---> 0.45\n",
      "Class name --> person\n",
      "Confidence ---> 0.34\n",
      "Class name --> person\n",
      "Speed: 4.7ms preprocess, 211.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 330.5ms\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Speed: 6.1ms preprocess, 330.5ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 255.1ms\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.44\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Speed: 6.2ms preprocess, 255.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 232.5ms\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.74\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.57\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Confidence ---> 0.26\n",
      "Class name --> person\n",
      "Speed: 5.5ms preprocess, 232.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 273.2ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.48\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> person\n",
      "Confidence ---> 0.38\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 5.2ms preprocess, 273.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 312.3ms\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.67\n",
      "Class name --> person\n",
      "Confidence ---> 0.59\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 4.6ms preprocess, 312.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 280.2ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> person\n",
      "Confidence ---> 0.55\n",
      "Class name --> person\n",
      "Confidence ---> 0.5\n",
      "Class name --> person\n",
      "Confidence ---> 0.4\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Speed: 5.6ms preprocess, 280.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 280.7ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.68\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.42\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> person\n",
      "Speed: 6.0ms preprocess, 280.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 214.9ms\n",
      "Confidence ---> 0.91\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.54\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "Confidence ---> 0.33\n",
      "Class name --> person\n",
      "Speed: 4.9ms preprocess, 214.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 chair, 214.3ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> person\n",
      "Confidence ---> 0.61\n",
      "Class name --> person\n",
      "Confidence ---> 0.41\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> chair\n",
      "Speed: 4.4ms preprocess, 214.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 276.2ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.79\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.64\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> chair\n",
      "Speed: 4.0ms preprocess, 276.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 1 laptop, 200.8ms\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.85\n",
      "Class name --> person\n",
      "Confidence ---> 0.8\n",
      "Class name --> laptop\n",
      "Confidence ---> 0.78\n",
      "Class name --> person\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> person\n",
      "Confidence ---> 0.28\n",
      "Class name --> chair\n",
      "Speed: 4.1ms preprocess, 200.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 laptop, 199.2ms\n",
      "Confidence ---> 0.93\n",
      "Class name --> person\n",
      "Confidence ---> 0.82\n",
      "Class name --> person\n",
      "Confidence ---> 0.71\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> person\n",
      "Confidence ---> 0.47\n",
      "Class name --> person\n",
      "Confidence ---> 0.32\n",
      "Class name --> laptop\n",
      "Speed: 4.7ms preprocess, 199.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 308.7ms\n",
      "Confidence ---> 0.92\n",
      "Class name --> person\n",
      "Confidence ---> 0.88\n",
      "Class name --> person\n",
      "Confidence ---> 0.73\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> person\n",
      "Confidence ---> 0.43\n",
      "Class name --> person\n",
      "Confidence ---> 0.37\n",
      "Class name --> person\n",
      "Confidence ---> 0.31\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> chair\n",
      "Confidence ---> 0.28\n",
      "Class name --> person\n",
      "Speed: 4.1ms preprocess, 308.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math \n",
    "# start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# model\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "# object classes\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    # coordinates\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            # bounding box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "            # put box in cam\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # confidence\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            print(\"Confidence --->\",confidence)\n",
    "\n",
    "            # class name\n",
    "            cls = int(box.cls[0])\n",
    "            print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "            # object details\n",
    "            org = [x1, y1]\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontScale = 1\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 2\n",
    "\n",
    "            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
    "\n",
    "    cv2.imshow('Webcam', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e826f1d-3cd5-490a-96c3-25d68d640db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\saiprithi\\\\Documents\\\\naresh it\\\\datasience ai\\\\DEEPLEARNIG\\\\yolo_p'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1712544-5c8e-49ea-a438-33e7c0cbb21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7674b2-209f-46e6-a534-d0f39632fe9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184d60b-b0c8-44c5-b1e4-e5efdb1ed6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d1f210-993e-4082-a191-629872fa6ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c785c0a-7907-4d1f-829d-5cb72029a8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed80b21-d836-4f6e-8f9d-6054ccebb2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac24e3c8-93cc-46aa-8fea-91758424ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Failed to open video C:\\Users\\omkar\\OneDrive\\Documents\\Data science\\Naresh IT\\Naresh IT\\OpenCV\\videos\\los_angeles_out.mp4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo-Weights/yolov8n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Start tracking objects in a video\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# You can also use live video streams or webcam input\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model\u001b[38;5;241m.\u001b[39mtrack(source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124momkar\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData science\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNaresh IT\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNaresh IT\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOpenCV\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvideos\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlos_angeles_out.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:602\u001b[0m, in \u001b[0;36mModel.track\u001b[1;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# batch-size 1 for tracking in videos\u001b[39;00m\n\u001b[0;32m    601\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source\u001b[38;5;241m=\u001b[39msource, stream\u001b[38;5;241m=\u001b[39mstream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:555\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor(source\u001b[38;5;241m=\u001b[39msource, stream\u001b[38;5;241m=\u001b[39mstream)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:226\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_model(model)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:  \u001b[38;5;66;03m# for thread-safe inference\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# Setup source every time predict is called\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_source(source \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msource)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# Check if save_dir/ label file exists\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_txt:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:198\u001b[0m, in \u001b[0;36mBasePredictor.setup_source\u001b[1;34m(self, source)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgsz \u001b[38;5;241m=\u001b[39m check_imgsz(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mimgsz, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstride, min_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# check image size\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    197\u001b[0m )\n\u001b[1;32m--> 198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m load_inference_source(\n\u001b[0;32m    199\u001b[0m     source\u001b[38;5;241m=\u001b[39msource,\n\u001b[0;32m    200\u001b[0m     batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch,\n\u001b[0;32m    201\u001b[0m     vid_stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvid_stride,\n\u001b[0;32m    202\u001b[0m     buffer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mstream_buffer,\n\u001b[0;32m    203\u001b[0m )\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39msource_type\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mstream\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mscreenshot\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# many images\u001b[39;00m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;28;01mFalse\u001b[39;00m]))\n\u001b[0;32m    210\u001b[0m ):  \u001b[38;5;66;03m# videos\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\data\\build.py:202\u001b[0m, in \u001b[0;36mload_inference_source\u001b[1;34m(source, batch, vid_stride, buffer)\u001b[0m\n\u001b[0;32m    200\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m LoadPilAndNumpy(source)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m LoadImagesAndVideos(source, batch\u001b[38;5;241m=\u001b[39mbatch, vid_stride\u001b[38;5;241m=\u001b[39mvid_stride)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# Attach source types to the dataset\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28msetattr\u001b[39m(dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, source_type)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\data\\loaders.py:312\u001b[0m, in \u001b[0;36mLoadImagesAndVideos.__init__\u001b[1;34m(self, path, batch, vid_stride)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbs \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(videos):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_video(videos[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# new video\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\data\\loaders.py:382\u001b[0m, in \u001b[0;36mLoadImagesAndVideos._new_video\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcap\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FPS))\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to open video \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcap\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FRAME_COUNT) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvid_stride)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Failed to open video C:\\Users\\omkar\\OneDrive\\Documents\\Data science\\Naresh IT\\Naresh IT\\OpenCV\\videos\\los_angeles_out.mp4"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLO model\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "# Start tracking objects in a video\n",
    "# You can also use live video streams or webcam input\n",
    "model.track(source=r\"C:\\Users\\omkar\\OneDrive\\Documents\\Data science\\Naresh IT\\Naresh IT\\OpenCV\\videos\\los_angeles_out.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f0e5fb3-1632-44c1-b2ee-74d004a0ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d04703d-8e86-4c1e-bf7b-9781c1dfb766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e9ae2d-f8f0-4e70-aa2b-7fb43b73f09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
